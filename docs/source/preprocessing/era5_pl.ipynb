{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 data at pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import yaml\n",
    "\n",
    "from preprocessing import (get_grid_info, insert_level, interpolate,\n",
    "                           sortby_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "g = 9.80665  # [m/s2]\n",
    "density_water = 1000  # [kg/m3]\n",
    "\n",
    "# Read case configuration\n",
    "with open(\"cases/era5_2013.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Create the preprocessed data folder if it does not exist yet\n",
    "output_dir = Path(config[\"preprocessed_data_folder\"]).expanduser()\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def load_data(variable, date):\n",
    "    \"\"\"Load data for given variable and date.\"\"\"\n",
    "    filepath = Path(config[\"input_folder\"]) / f\"FloodCase_201305_{variable}.nc\"\n",
    "    da = xr.open_dataset(filepath)[variable]\n",
    "\n",
    "    # Include midnight of the next day (if available)\n",
    "    extra = date + pd.Timedelta(days=1)\n",
    "    return da.sel(time=slice(date, extra))\n",
    "\n",
    "\n",
    "datelist = pd.date_range(\n",
    "    start=config[\"preprocess_start_date\"],\n",
    "    end=config[\"preprocess_end_date\"],\n",
    "    freq=\"d\",\n",
    "    inclusive=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in datelist[:]:\n",
    "    print(date)\n",
    "\n",
    "    # 4d fields\n",
    "    q = load_data(\"q\", date)  # in kg kg-1\n",
    "    u = load_data(\"u\", date)  # in m/s\n",
    "    v = load_data(\"v\", date)  # in m/s\n",
    "\n",
    "    # Precipitation and evaporation\n",
    "    evap = load_data(\"e\", date)  # in m (accumulated hourly)\n",
    "    cp = load_data(\"cp\", date)  # convective precipitation in m (accumulated hourly)\n",
    "    lsp = load_data(\"lsp\", date)  # large scale precipitation in m (accumulated hourly)\n",
    "    precip = cp + lsp\n",
    "\n",
    "    # TODO: not used\n",
    "    tcw = load_data(\"tcw\", date)  # kg/m2\n",
    "\n",
    "    p_surf = load_data(\"sp\", date)  # in Pa\n",
    "    d_surf = load_data(\"d2m\", date)  # Dew point in K\n",
    "    u_surf = load_data(\"u10\", date)  # in m/s\n",
    "    v_surf = load_data(\"v10\", date)  # in m/s\n",
    "    q_surf = calculate_humidity(d2m, p_surf)  # kg kg-1\n",
    "\n",
    "    # Get grid info\n",
    "    time = u.time.values\n",
    "    lat = u.latitude.values\n",
    "    lon = u.longitude.values\n",
    "    a_gridcell, l_ew_gridcell, l_mid_gridcell = get_grid_info(u)\n",
    "\n",
    "    # Calculate volumes\n",
    "    # TODO: shall we do this in the tracking?\n",
    "    evap *= a_gridcell[None, :, None]  # m3\n",
    "    precip *= a_gridcell[None, :, None]  # m3\n",
    "\n",
    "    # Transfer negative (originally positive) values of evap to precip\n",
    "    precip = np.maximum(precip, 0) + np.maximum(evap, 0)\n",
    "    # Change sign convention to all positive,\n",
    "    evap = np.abs(np.minimum(evap, 0))\n",
    "\n",
    "    # Create pressure array with the same dimensions as u, q, and v\n",
    "    p = u.level.broadcast_like(u)\n",
    "\n",
    "    # Insert top of atmosphere values\n",
    "    u = insert_level(u, u.isel(level=0), 0)\n",
    "    v = insert_level(v, v.isel(level=0), 0)\n",
    "    q = insert_level(q, q.isel(level=0), 0)\n",
    "    p = insert_level(p, 0, 0)\n",
    "\n",
    "    # Insert surface level values\n",
    "    u = insert_level(u, u_surf, 110000)\n",
    "    v = insert_level(v, v_surf, 110000)\n",
    "    q = insert_level(q, q_surf, 110000)\n",
    "    p = insert_level(p, p_surf, 110000)\n",
    "\n",
    "    # Sort arrays by pressure (ascending)\n",
    "    u.values = sortby_ndarray(u.values, p.values, axis=1)\n",
    "    v.values = sortby_ndarray(v.values, p.values, axis=1)\n",
    "    q.values = sortby_ndarray(q.values, p.values, axis=1)\n",
    "    p.values = sortby_ndarray(p.values, p.values, axis=1)\n",
    "\n",
    "    # Insert boundary level values (at a ridiculous dummy pressure value)\n",
    "    p_boundary = 0.72878581 * np.array(p_surf) + 7438.803223\n",
    "    u = insert_level(u, interpolate(p_boundary, p, u), 150000)\n",
    "    v = insert_level(v, interpolate(p_boundary, p, v), 150000)\n",
    "    q = insert_level(q, interpolate(p_boundary, p, q), 150000)\n",
    "    p = insert_level(p, p_boundary, 150000)\n",
    "\n",
    "    # Sort arrays by pressure once more (ascending)\n",
    "    u.values = sortby_ndarray(u.values, p.values, axis=1)\n",
    "    v.values = sortby_ndarray(v.values, p.values, axis=1)\n",
    "    q.values = sortby_ndarray(q.values, p.values, axis=1)\n",
    "    p.values = sortby_ndarray(p.values, p.values, axis=1)\n",
    "\n",
    "    # Reset level coordinate as its values have become meaningless\n",
    "    nlev = u.level.size\n",
    "    u = u.assign_coords(level=np.arange(nlev))\n",
    "    v = v.assign_coords(level=np.arange(nlev))\n",
    "    q = q.assign_coords(level=np.arange(nlev))\n",
    "    p = p.assign_coords(level=np.arange(nlev))\n",
    "\n",
    "    # Calculate pressure jump\n",
    "    dp = p.diff(\"level\")\n",
    "    assert np.all(dp > 0), \"Pressure levels should increase monotonically\"\n",
    "\n",
    "    # Interpolate to midpoints\n",
    "    midpoints = 0.5 * (u.level.values[1:] + u.level.values[:-1])\n",
    "    u = u.interp(level=midpoints)\n",
    "    v = v.interp(level=midpoints)\n",
    "    q = q.interp(level=midpoints)\n",
    "    p = p.interp(level=midpoints)\n",
    "    dp.assign_coords(level=midpoints)\n",
    "\n",
    "    # Determine the fluxes and states\n",
    "    fx = u * q * dp / g  # eastward atmospheric moisture flux (kg*m-1*s-1)\n",
    "    fy = v * q * dp / g  # northward atmospheric moisture flux (kg*m-1*s-1)\n",
    "    cwv = q * dp / g * a_gridcell[None, None, :, None] / density_water  # column water vapor (m3)\n",
    "\n",
    "    # Integrate fluxes and state\n",
    "    upper_layer = p < p_boundary[:, None, :, :]\n",
    "    lower_layer = ~upper_layer\n",
    "\n",
    "    fx_lower = fx.where(lower_layer).sum(dim=\"level\")  # kg*m-1*s-1\n",
    "    fy_lower = fy.where(lower_layer).sum(dim=\"level\")  # kg*m-1*s-1\n",
    "    s_lower = cwv.where(lower_layer).sum(dim=\"level\")  # m3\n",
    "\n",
    "    fx_upper = fx.where(upper_layer).sum(dim=\"level\")  # kg*m-1*s-1\n",
    "    fy_upper = fy.where(upper_layer).sum(dim=\"level\")  # kg*m-1*s-1\n",
    "    s_upper = cwv.where(upper_layer).sum(dim=\"level\")  # m3\n",
    "\n",
    "    # Check column water vapor conservation\n",
    "    np.testing.assert_array_almost_equal(\n",
    "        cwv.sum(dim=\"level\"),\n",
    "        s_upper + s_lower,\n",
    "        err_msg=\"Column water vapor should be approximately 0\"\n",
    "    )\n",
    "\n",
    "    # Save preprocessed data\n",
    "    filename = f\"{date.strftime('%Y-%m-%d')}_fluxes_storages.nc\"\n",
    "    output_path = output_dir / filename\n",
    "\n",
    "    xr.Dataset(\n",
    "        {  # TODO: would be nice to add coordinates and units as well\n",
    "            \"fx_upper\": fx_upper,\n",
    "            \"fy_upper\": fy_upper,\n",
    "            \"fx_lower\": fx_lower,\n",
    "            \"fy_lower\": fy_lower,\n",
    "            \"s_upper\": s_upper,\n",
    "            \"s_lower\": s_lower,\n",
    "            \"evap\": evap,\n",
    "            \"precip\": precip,\n",
    "        }\n",
    "    ).to_netcdf(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('wam2layers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a20d0a8427cf157660a5f7831b5ea181b2261d0622e99d9dfb33ceae678266e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
